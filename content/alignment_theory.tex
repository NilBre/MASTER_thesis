\chapter{The Theory of Alignment}
\label{sec:alignTheory}

short introduction

\section{Track Reconstruction}
\label{sec:kalman}

In order for LHCb to be used for physics, all of the detector hit information has to be converted into tracks, which is a challenging task.
The track reconstruction algorithm needs to find the correct hits from each subdetector to build the track. This can be problematic just because of the amount of tracks per events (roughly 100).
It is crucial to find all particle tracks and also their track parameters which come from the track fit.

A good track fit is needed in order to find to best estimates for the track parameters and covariances. The estimates are used in the event reconstruction to find the correct tracks for each particle and the decay products. The info provided is used in the RICH rings, ECAL and HCAL and muon detectors. With these information, particle and track parameters such as the invariant mass can be measured and vertex origins can be found.
There are several track models that can be used. In general, a track is build from numerous segments which are either straight or curved because of an active magnetic field. Depending on the environment of the track either model is good.
The track segments are called track states and are defined by a position in $x$ and $y$ at a given distance $z$ where the hit was located, then a tanget direction $t_{x,y}$ at the hit position and a momentum parameter acquired from the track curve inside the magnetic field\cite{VanTilburg}.

In order to correctly reconstruct the track it is important to know where the hit is localized and for the upcoming hits, where to particle track came from. From the momentum measurement of the track curvature caused by the magnetic field, the parameter $q/p$ is also added.

\begin{align*}
  \vec{r} = \left(\begin{array}{c} x \\ y \\ t_x \\ t_y \\ \frac{q}{p}\end{array}\right) &\,\, t_x = \frac{\partial x}{\partial z} & t_y = \frac{\partial y}{\partial z}
\end{align*}

The uncertainty of the five-component state vector is a $5\times5$ covariance matrix $C$.
A track state can be anywhere on the trajectory but is easier to choose it at real detection points. Combining the track state with a real measurement point is called \textit{node}.
The propagation from node $k-1$ to node $k$ is described by a propagation function

\begin{equation*}
  \vec{r}_k = f_k(\vec{r}_{k_{-1}}) + \vec{w}_k\,.
\end{equation*}

This means node $k$ is acquired by propagating node $k-1$ through the propagation function $f_k$ and shifting it by the \textit{process noise} $\vec{w}_k$.
% Process noise can be caused by any scattering phenomenon that may have happened.
LHCb uses process noise to model the scattering.
Depending on the type of propagation, linear or curved, a different propagation function is used.
for a linear extrapolation, $f_k$ results in
\begin{equation*}
  f_k \left(\vec{r}_{k-1}\right) = F_k \vec{r}_{k-1}
\end{equation*}
with the transport matrix $F_k$
\begin{gather*}
  F_K = \begin{pmatrix}
    1 & 0 & \Delta z & 0 & 0 \\
    0 & 1 & 0 & \Delta z & 0 \\
    0 & 0 & 1 & 0 & 0 \\
    0 & 0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 0 & 1 \\
  \end{pmatrix}
\end{gather*}
and $\Delta z$ being the difference in z between the nodes
\begin{equation*}
  \Delta z = z_k - z_{k-1}
\end{equation*}

Trajectory information for each node is provided by the real measurement where the relation between measurement $m_k$ and track state at a given node $k$ is defined as

\begin{equation*}
  m_k = h_k(\vec{r}_k) + \epsilon_k
\end{equation*}

with the projection function $h_k$ and \textit{measurement noise} $\epsilon_k$.
So if the detector only measures the $y$ coordinate of state, the projection function
will be
\begin{equation*}
  h_k(\vec{r}_k) = H_k \vec{r}_k
\end{equation*}
with
\begin{gather*}
  H_k = \begin{pmatrix}
    0 & 1 & 0 & 0 & 0 \\
  \end{pmatrix}
\end{gather*}\,.

When measuring more parameters the measurement matrix $H_k$ and projection matrix have dimension $n\times5$ with $n$ being the numbers of parameters measured.

With this track model, $\epsilon_k$ and $w_k$ are random and unknown and have an expectation value of zero.
% They are defined as $W_k \equiv cov(w_k)$ and $V_k \equiv cov(\epsilon_k)$.

% now kalman filter formalism
\section{The Kalman filter method \cite{VanTilburg}}
In general a track is an ensemble of measurements and track states and the Kalman filter method is used to fit tracks.
The idea of the Kalman filter is, to have a starting node and add measurements one by one. In between the addition of measurements, the local track state is updated with the new information.
The Kalman filter method is a $\chi^2$ minimising problem for the measurement of the track. Because of the iterative nature of the method, it is fast und also used in other fields than physics, for example GPS and meteorology.
The three steps of the Kalman filter will be briefly outlined and later discribed in further detail.

The first step is the $\symbf{Prediction}$: The next track state of the trajectory is predicted based on the track state at the previous node.
The second step is the $\symbf{Filter}$ procedure: By using filter equation*s, the prediction is updated with measurement information in this node. The prediction and filter are repeated for each measurement. With more measurements added, the estimate for the best trajectory is the track state after each filter step.
The final step is called $\symbf{Smoother}$: When the trajectory is complete, smoother equation*s are applied from the last node to the previous node. Therefore the information from all measurements is used in both forward- and backpropagation which results in a more
defined track.

\subsection{first Step: Prediction}
For a given state vector at node \textit{k-1}, the prediction for the $k^{\text{th}}$ state vector and its covariance matrix results from the propagation relations

\begin{align*}
  \vec{r}_p^{k-1} &= f_p\left( \vec{r}_{k-1} \right) \\
  \text{Cov}_k^{k-1} &= F_k C_{k-1} F_k^T + Q_k
\end{align*}

The superscript of the statevector shows the amount of information used in the estimate.
That means $\vec{r}_k^n$ is the smoothed state vector which used all information,
$\vec{r}_k^k-1$ is the predicted state vector and $\vec{r}_k^k \equiv \vec{r}_k$ is the filtered state.

$Q_k$ is the process noise in matrix form and it is part of the predicted
covariance matrix $C_k^{k-1}$.
Because the first state cannot take measurements from the previous state, an initial prediction is taken from the track finding algorithm instead.
The predicted residual between the measurement, $m_k$ and the state vector results in
\begin{equation*}
  \text{res}_k^{k-1} = m_k - h_k\left( \vec{r}_k^{k-1} \right)
\end{equation*}
and the corresponding covariance matrix is defined as
\begin{equation*}
  \text{Cov}_{\text{res},k}^{k-1} = V_k + H_k C_k^{k-1} H_k^T\,.
\end{equation*}

Here, $V_k$ is the measurement variance. With these metrics the minimal $\chi^2$ for the optimal track states can be calculated via
\begin{equation*}
  \left( \chi^2 \right)_k^{k-1} =
  \text{res}_k^{k-1} \left(\text{Cov}_{\text{res},k}^{k-1}\right)^{-1} \text{res}_k^{k-1}
\end{equation*}

\subsection{second Step: Filter}
During the filter step, the track state is updated with the measurement information.
Iteratively, each measurement is added and the filtered state $\vec{r}_k$ and the corresponding covariance matrix is calculated via
\begin{align*}
  \vec{r}_k &= \vec{r}_k^{k-1} + G_p \text{res}+k^{k-1} \\
  \text{Cov}_k &= \left(\mathbb{1} - G_k H_k\right) \text{Cov}_k^{k-1}\,,
\end{align*}
where $G_k$ is the gain matrix of dimension $5\times1$ and is defined as
\begin{equation*}
  G_k = C_k^{k-1} H_k^T \left( \text{Cov}_{\text{res},k}^{k-1} \right)^{-1}
\end{equation*}

Afterwards the residuals and its covariance matrix are calculated and the filtered total $\chi^2$ is defined as
\begin{equation*}
  \left( \chi^2_{\text{filter}} \right)_k = \text{res}_k \text{Cov}_{\text{res},k}^{-1} \text{res}_k\,.
\end{equation*}

The prediction and filter procedure is continued for all measurements until the track is fully reconstructed.
Because the last node at $k \, = \, n$ has the most information in it, a backward update is performed to infuse the previous nodes with the same information as in last node.
This is called \textit{smoother}-step.

\subsection{third Step: Smoother}
The smoother function returns the best possible estimate for track states at
the previous nodes. The method used is called \textit{Rauch-Tung-Striebel}-smoother\cite{RTS}.
The idea is to use backward information and construct a smoothed state vector and covariance matrix
\begin{align*}
  \tilde{r}_k^n &= \vec{r}_k + S_k \left( \vec{r}_{k+1}^n - \vec{r}_{k+1}^k \right) \\
  \tilde{C}_k^n &= C_k
\end{align*}
and the Smoother-matrix $S_k$ of dimension $5\times5$
\begin{equation*}
  S_k = C_k F_{k+1}^T \left( C_{k+1}^p \right)^{-1}\,.
\end{equation*}

In order to calculate the smoothed $\chi^2$ the residual and correspending covariance matrix are
\begin{align*}
  \text{res}_k &= m_k - h_k \vec{h}_k^n \\
  \text{Cov}_{\text{res},k}^n &= V_k - H_k C_k^n H_k^T
\end{align*}

The $\chi^2$ is calculated analogously to the one during the filter step with the difference being the new residuals and covariances.

\section{Alignment with Kalman filter track fit}
\label{sec:derivatives}

In principal, minimizing the track residuals is the obvious way to align a detector.
The residual $\vec{\text{res}}_k$ is defined by the difference between a real detector hit and the expected hit position

\begin{equation}
  \text{res}_k = m_k - h_k(\vec{r},\vec{\alpha})
\end{equation}

where $\symbf{h}$ is the measurement model, $\vec{r}$ are the track parameters and $\vec{\alpha}$ are the alignment parameters.
Aligning the SciFi by minimizing the track $\chi^2$ with the same model as used for reconstruction is an advantage. The idea is to use a global covariance matrix in the Kalman filter track fit. Fiiting the tracks will be the form of alignment.
In the following paragraph this form of alignment is briefly described from the in-depth demonstration from Wouter Hulsbergen\cite{HULSBERGEN1}.

Starting with a short revisit about the important aspects of the Kalman track reconstruction. The track $\chi^2$ is defined as

\begin{equation}
  \chi^2 = \vec{\text{res}}^T V^{-1} \vec{\text{res}}\,,
\end{equation}

where $V$ is the track covariance matrix.
The condition for $\chi^2$ to be minimal with respect to a track model $h(x,\alpha)$ with track parameters $x_k$ and alignment parameters $\alpha_k$ are

\begin{equation}
  \frac{\partial\sum_k\chi^2_k}{\partial \alpha} = 0
\end{equation}

 and

 \begin{equation}
   \forall_k \frac{\partial\chi^2_k}{\partial x_k} = 0\,.
 \end{equation}

The subscript $k$ denotes the track not the vector component. For a single track the subscript can be left out. For many tracks to computation is performed in two steps because it is computational too expensive to use a least square expression.
The first step is to estimate track parameters for a starting set of calibration parameters called $\alpha_0$. The second step is to minimize the total $\chi^2$ with respect to $\alpha$ while also taking $x_k$ and $\alpha$ into account.

The total derivative reads
\begin{equation}
  \frac{\symup{d}}{\symup{d}\alpha} = \frac{\partial}{\partial\alpha} +
  \frac{\symup{d}x}{\symup{d}\alpha}\frac{\partial}{\partial x}\,.
\end{equation}

$\frac{\symup{d}x}{\symup{d}\alpha}$ is a derivative matrix and results from the minimal track $\chi^2$ condition and can be expressed by

\begin{equation}
  \frac{\symup{d}}{\symup{d}\alpha}\frac{\partial \chi^2}{\partial x} = 0
\end{equation}

therefore the derivative matrix is definded as
\begin{equation}
  \frac{\symup{d}x}{\symup{d}\alpha} = -\frac{\partial^2\chi^2}{\partial\alpha\partial x} \left( \frac{\partial^2\chi^2}{\partial x^2} \right)^{-1}\,.
\end{equation}

The total $\chi^2$ for a sample of tracks is minimal with respect to $\alpha$ and $x$ can the be described as
\begin{equation}
  \frac{\symup{d}\chi^2}{\symup{d}\alpha} = 0\,.
\end{equation}

For $N$ alignment parameters a system with $N$ coupled non-linear equations is defined.
Linearizing the minimum $\chi^2$ condition around the starting values $\alpha_0$ and solving the linear system for $\Delta\alpha$ yields the solution.
\begin{equation}
  \frac{\symup{d}^2\chi^2}{\symup{d}\alpha^2}\vert_{\alpha_0} \Delta\alpha =
  -\frac{\symup{d}\chi^2}{\symup{d}\alpha}\vert_{\alpha_0}
\end{equation}

Now, with enough constraints inside the alignment the second derivative matrix is invertable and the covariance matrix for $\alpha$ reads

\begin{equation*}
  \text{Cov}(\alpha) = 2 \left( \frac{\symup{d}^2\chi^2}{\symup{d}\alpha^2} \right)^{-1}\,.
\end{equation*}

Higher order derivatives in $\alpha$ are neglected here. The difference in the total $\chi^2$ resulting from a change in $\Delta\alpha$ is given by

\begin{equation*}
  \Delta_{\chi^2} = \frac{1}{2} \left( \frac{\symup{d}\chi^2}{\symup{d}\alpha} \right)^T \Delta\alpha = -\Delta\alpha^T \text{Cov}(\alpha)^{-1}\Delta\alpha
\end{equation*}

The change in total $\chi^2$ is equivalent to the significance of the alignment correction and $\Delta_{\chi^2}$ is used to follow the convergence of an alignment.
